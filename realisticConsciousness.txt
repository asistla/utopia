The problem of consciousness has been open for atleast a few thousand years. Recent years have seen some truly astounding breakthroughs in understanding the brain and its function, as well as great steps in our understanding 
of how its physical function gives rise to particular subjective experiences, but the moat between what the brain does, and what happens because of it, remains unscathed. This is frustrating, and a little humiliating, but 
also, and crucially, dangerous; our inability to understand and explain such a basic and ubiquitous part of the experience of being human, arguably our paramount purpose as a species, has seen entire cultures rise around 
particular interpretations of it.

Simultaneously, the recent media frenzy around large language models, and the subsequent debates about the likelihood of LLMs, or AI in general, suddenly becoming conscious (because we want sentient AI, and sentience requires 
consciousness), have shown that we are also quite willing to substantially diminish the definition of consciousness itself in order to make AI fit the definition. Of course, this is a fundamentally pointless exercise; the 
definition of consciousness, like the definition of every word in every language humans have ever developed, is a matter of agreement, and has no inherent cosmic importance. Therefore, we can play around with the definitions, 
but unless the underlying phenomenon are explained, well, nothing has been achieved. We know this, which is what makes the persistent debates about the definitions so frustrating; because we have not yet agreed on a solid 
definition or description of consciousness, what is considered to be part of it is a matter of opinion, so explaining this vague cloud of characteristics that include properties, behaviors, and our subjective experience 
of the consequences, is clearly impossible, as evidenced by a thousand years of failure.

The hard problem of consciousness, in my view, is hard precisely because of how ambitiously its scope is assumed, and how overbroad the problem is made to be. Suppose I wanted to explain flames. I know the physical basis of a 
flame; the volatiles and combustible particulates burn in atmospheric oxygen creating a stream of gas that is hot enough to glow in the visible range. However, my subjective experience of direct physical interactions 
involving contact, is invariably of painful burns. In fact, it doesn't matter what the flame looks like, or whether it even is visible - if I touch it, it will burn me. None of that, however, makes painful burns a property of 
flames, but merely a consequence of exactly one physical property of a flame, the temperature - interacting with our skin directly which first leads to whatever physical effects flames have on skin like blisters and melted 
skin, after which the nerves take over, and ultimately, the brain. This is where pain 'forms' and is felt, so the correct interpretation is to realize that the flame itself does little to actually create the pain, even though 
it is ultimately the root cause of this experience. The combustible particles are certainly very hot, but the reason we feel it in the first place is purely physical; thermodynamics demands uniform energy distribution across 
a system, so the moment our hands touch the flame, heat wants to travel into the hand, causing damage and pain. But the flame itself had nothing to do with it, and it is actually the fuel itself and the temperature it is 
burning at, that determines the temperature and the effect the flame will have on the body. To put simply: neither the burn, nor the pain, are truly a property of the flame.

This is, I claim, a somewhat silly analogy to the very real problem of including the effects and consequences of a process as a property of that process. For example, introspection is classically considered an 
integral, and arguably inseperable part of consciousness and the subjective experience of 'being'. This, however, is inaccurate - consciousness is certainly a part of it, but introspection is the combination of 
consciousness, with linguistic and analytical skills employed to analyze ones own behavior and mental state. If one were to remove the analytical and linguistics aspects of introspection, one would expect to be left with pure 
consciousness, and in this view, pure consciousness would simply be the facility of sensing the brain's state.

Finallly, a disclaimer: the general pattern of the arguments that follow will reply on liberal oversimplifications, overbroad generalizations and a very superficial, logical analysis. The result is not expected to be a description
of reality, and shouldn't be seen as such. Instead, the goal is simply to prompt fresh discussions from a different point of view, with the hope that a review of the problem statement itself might lead to some insights.


1. What are we dealing with?

We are trying to come up with a view of consciousness that is internally consistent, consistent with all our observations and experiences, and hopefully makes predictions that can be tested. Note that there still is no 
solution to the ultimate problem of actually testing for consciousness itself. I will attempt to argue that this is actually impossible within the following treatment of consciousness.

We start with a simple example of a sensory process that ends with subjective perception, such as sight. In its simplest and most accurate definition, sight is the perception of ambient electromagnetic radiation within a 
 certain range of frequencies. We know how this works; lenses focus ambient light onto the retina, which then sends electrical impulses into the brain. This is the end of the track, and we do not know what happens between 
 this point, and the subjective experience of this picture of reality that is known, internally. We can trace a purely physical process of perception until it reaches the brain, at which point, by 'some magic', this 
 perception becomes available as internalized information, even if transient. 

Going back to our definition of sight, as the perception of ambient electromagnetic radiation within a certain range of frequencies, we notice that while this is a complete and accurate definition of sight, the word 
 'perception' actually hides a lot of the complexity and mystery we associate with conscious subjective experience. In particular, what is 'perceived' is not what is actually captured by the eyes - the moment light hits the 
 retina, or sound hits the eardrum, or any other stimulus turns into an electrical impulse, we are for all intents and purposes, detached from reality; we must navigate our universe relying exclusively on the stories our 
 brain makes up. In fact, this reality is not even 'directly' available to the brain, which must make do with the electrical impulses which are not nearly 'consistent' enough to serve as a reliable signal (exactly identical 
 images do not cause exactly identical retinal impulses), seen within the context of what it has experienced in the past. The conscious perception of our surroundings, visual or otherwise, is the culmination of a rather 
 complex (inasmuch as we know little about it) computation involving the brain's past experiences with visual stimuli, within the context of its experiences and learned patterns considering all other senses, ending with a 
 nearly infallible guess of reality. Only the first step of this process has anything to do with actual reality; the rest is functionally identical to large language models - generate from a 'prompt' consisting of neural 
 impulses from sensory organs, based on patterns discovered in past 'experiences'. This picture is complete and accurate, until the point preceding the actual subjective experience. This is important; the entire process of 
 perception, functionally, is clearly separable into two parts. The first is what the brain does (note that we only need the what, not the how or why). The second, is the matter of the subjective experience. We do not want to 
 attach more properties to our view of consciousness unless we need to, because the larger the circle around what we consider consciousness, the harder it is to explain all its myriad aspects. So how simply can we define 
 consciousness, while preserving all properties that are commonly considered part of it? A very good candidate is simply "awareness of our internal state". This definition is vague, and leaves the burden of defining what 
 'awareness' is, and what constitutes an 'internal state'; but with a strictly colloqual reading, this is an accurate, if incomplete description of what most would agree constitutes consciousness.

Now consider the following: in typical non-pathological scenarios, the visual perception of the world must begin with organs that are specifically designed to sense light. The rest can be made up, but the initial prompt must be 
from a source that actually can sense reality. If we instead draw a larger box to capture everything that can be directly attributed to physical effects in the process of perception, namely, the light, the eyes, the nerves, 
the brain, and all the electrochemical activity that we know occurs, ending with this picture that we know the brain creates, the question of perception is therefore reduced to somehow, sensing this picture the brain has 
created. Further, this 'picture' is a catch-all for all we know the brain can do - thought, perception, emotional responses, and so on. Every aspect of our conscious, subjective experience of reality, everything we think, 
everything we see, hear, love, hate, anger, happiness, self-hate and ideas of self-harm, are ultimately pure creations of the brain. In addition, these creations are not tangible objects that are passed on to the magical 
agent of consciousness, but absolutely intangible events that cannot be separated into further steps(FUNCTIONALLY); we can discern no sequence of steps either in the creation of this picture itself, nor in the perception of 
this picture. In this abstract view, all of perception, emotion, and thought, therefore results in what can best be described as 'some' state of the brain. This state involves certain regions of the brain being active, 
certain neurons firing in specific ways in specific directions, a process too hopelessly complicated to actuallly track physically, but we only need to know that the brain has now gone from one state to another, the first being 
the moment preceding subjective experience, and the latter, during, with all the insanity taking place during the transition.

We know consciousness and subjective experience ultimately must have a physical origin, but we also know the subjective experience of reality is itself not physical. If we simply separate the physical, the universe and all 
the brain does, from the non-physical, what this results in internally, and force the same logic, that the perception of all physical stimuli requires some way of sensing it, then the brain's state must need a sensory organ 
as well. Resist any temptations to include the entire range of our subjective experiences and the 'magic' therein, poetry or love or whatever else, from what actually happens - burns are not a property of flames, but a 
consequence. From a purely functional perspective, it is reasonable to suggest that because the brain creates these intangible pictures of reality, pictures consisting of visuals, audio, smell, temperature, emotion - an agent 
that actually senses these states, collating all these diverse sources of information and the cryptic mess of electrical discharges, into some coherent picture of reality, which must then be 'available' as an actual picture, 
rather than a set of properties, like a photograph versus a list of RGB values.

Simultaneously, because the brain is ultimately incharge of nearly everything the body does (ignoring the specifics of the autonomous nervous system, for example, which involves the brain stem and the spine), it is sufficient 
for the brain to have some mechanism of turning these impulses into a 'known' picture of reality. In other words, a purely non-physical, that is, brain-generated 'sensory' system that can manage this effect will suffice, 
needing no additional hardware at all, neural or otherwise. Note that the claim is not that this is the correct picture of what goes on between the brain's actions and the effects on our subjective experience, but instead,
that even this oversimplified picture explains everything we observe. Further, in order to determine if this is possible at all, we only need to recognize the existence of software - purely 'abstract' entities with definite
physical origins, but abstracted to such an extent that direct correlations between the results and the physical causes are practically impossible to identify, even if they exist.
The brain, in this view, is comparable to a bare-metal computer, relying only on its internal physical and logical construction to perform actions that are 
determined by its physical state. The need for operating-systems in computing, is identical to the need for something resembling consciousness - a way to sense and interact with the hardware without needing to know the 
specifics of underlying physical events. It must be pointed out that conversely, not knowing or understanding the physical events underlying modern computing, is not a good reason to suggest that hypervisors or operating 
systems are conscious, sentient, intelligent, or a part of a unifying God-consciousness of which all virtual-machines are ultimately a part. 

To summarize, consciousness is effectively a 'software' sensory organ. Its sole and entire purpose is to 'sense' the brain's state as a coherent picture collating every aspect of this state. Note that there is absolutely no
intelligence, self-awareness, or volition to consciousness in this view, and this is justified in the following section.

One obvious question here, is why one is needed. There are certainly a whole mess of retroactive explanations using some evolutionary logic, but the only fact of importance here is that evolution and natural selection do not 
actually select for the 'best' anything, whether physically or functionally; there is no qualititave comparision between different mutations that result in different behaviors and capacities. All natural selection is, is a 
matter of what allows an individual to live long enough to reproduce. Further, what happens to the individual after reproduction is entirely irrelevant from this perspective, and the entire process of natural selection 
simplifies to a race between death and reproduction. Further, the traits that persist do not need to actually produce any practical benefits; as long as they do not hurt the population's chances of reproducing to produce 
healthy offspring, they will persist. If there are mutations introduced, the individuals with mutations that hurt these chances will reproduce less (whether qualitatively or quantitatively) than the ones that do not, but most 
traits that persist in populations, especially as the context and circumstances diverge from the conditions that could have favoured those traits, it is possible to have superbly complex traits that offer absolutely no clear 
benefit. In fact, given that it is possible for bare-metal computers to exist, or even purely analog circuitry that can be designed to perform a wide range of tasks, it is atleast not necessary to be conscious, to be 
functional and competitive on an evolutionary scale. However, as all mutations that form the core of evolutionary progressions in species, are ultimately arbitrary - mutations are not chosen by the species - once 'some' 
rudimentary mechanism for sensing the state of the brain emerges, it only has to not pose a disadvantage to persist. On the other hand, the moment this becomes and inheritable trait, it allows for serious jumps in complexity 
of the underlying computer, in exactly the same way that the operating systems allow for elegant control of monstrously complicated hardware which would most likely be practically impossible otherwise.
Therefore, the very initial 'why', from an evolutionary perspective, is almost universally "by lucky accident".

We now explore a model that forms a convenient framework for viewing consciousness as a 'convenience' for the brain.


2. The monkey in the safe.

As discussed previously, we know the picture of reality that the brain makes up, is absolutely independent of both consciousness (which we have defined as the sense of the brain's internal state) and reality itself. Further, 
just as every physical stimulus we encounter must first be sensed directly, so must the physical state of the brain. The conscious perception of a self is merely the 'knower' invented to facilitate this process of 'knowing'. 
This might sound convoluted, but to start with, we can definitely say the brain is 'capable' of inventing this subjective self, so raw processing-power is no concern. In fact, if this 'knower', the subjective self, is seen as 
the whole identity of a person, stemming from a convenience-construction of the brain, while the typical function involves one identity that forms the center of the individual's life, the brain is actually capable of doing 
this several times over, with several distinct, and functionally 'complete' identities, as seen in patients with dissociative identity disorder. Schizophrenia, on the other hand, suggests that it is not only possible, but is 
nearly a rule, that any picture of reality that the brain invents, 'feels' real to the subjective self, as the same hardware that created the picture also created the agent that can perceive it. Crucially, there is absolutely 
no need for this subjective experience to have any bearing or basis in objective reality to feel subjectively valid, which is why telling a patient with schizophrenia that their particular hallucinations are not 'real' does 
little to help them, nor does them knowing change the occurence of these hallucinations. That is, this is not a problem of incorrect information - the presence of information that suggests the picture of reality under 
question is inaccurate, does not actually affect the picture at all. In fact, mental illnesses, especially those that involve one or more functional parts of the brain in overdrive, serve as a reminder of what the hardware is 
actually capable of, and more importantly, how quickly things go out of control when the hardware malfunctions.

The important thing to note here, is that what is sensed must significantly deviate from what is 'expected' before one can comment on the accuracy of the brain's picture of reality. The brain, and the consciousness that 
senses it, are operating with the same facts. All the linguistic, imaginative, emotive, and analytical capabilities the brain together created this picture, which is why delusions and deeply held beliefs are rarely 
self-correctable. (I only say rare because I do not want to rule it out altogether).

Consider the following scenario: We have a monkey locked in a safe. This safe is completely isolated from the universe, and has neither the capacity nor the intent to interact with anything outside this safe. Further, the 
ONLY stimulus available to this monkey is a television screen strapped to its head. The monkey has no control over what the television shows, nor on the volume, nor does it have the capacity to look away. In fact, the ONLY 
capability this monkey has, is to perceive what the screen says.


